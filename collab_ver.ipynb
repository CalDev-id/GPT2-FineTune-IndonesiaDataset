{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2143,
          "sourceType": "datasetVersion",
          "datasetId": 1192
        },
        {
          "sourceId": 7661496,
          "sourceType": "datasetVersion",
          "datasetId": 4467371
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bnsreenu/python_for_microscopists/blob/master/311_fine_tuning_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U PyPDF2\n",
        "!pip install python-docx"
      ],
      "metadata": {
        "id": "l9PhAQicEyQd",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:00.663097Z",
          "iopub.execute_input": "2024-02-20T07:25:00.663490Z",
          "iopub.status.idle": "2024-02-20T07:25:24.450070Z",
          "shell.execute_reply.started": "2024-02-20T07:25:00.663451Z",
          "shell.execute_reply": "2024-02-20T07:25:24.448479Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1da832e-5a4c-4324-e38a-08bbe1f513ab"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "import os\n",
        "import docx"
      ],
      "metadata": {
        "id": "ItYpaZD9EH7J",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.451761Z",
          "iopub.execute_input": "2024-02-20T07:25:24.452911Z",
          "iopub.status.idle": "2024-02-20T07:25:24.458049Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.452844Z",
          "shell.execute_reply": "2024-02-20T07:25:24.457094Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to read different file types\n",
        "def read_pdf(file_path):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        pdf_reader = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            text += pdf_reader.pages[page_num].extract_text()\n",
        "    return text\n",
        "\n",
        "def read_word(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\"\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + \"\\n\"\n",
        "    return text\n",
        "\n",
        "def read_txt(file_path):\n",
        "    with open(file_path, \"r\") as file:\n",
        "        text = file.read()\n",
        "    return text\n",
        "\n",
        "def read_documents_from_directory(directory):\n",
        "    combined_text = \"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            combined_text += read_pdf(file_path)\n",
        "        elif filename.endswith(\".docx\"):\n",
        "            combined_text += read_word(file_path)\n",
        "        elif filename.endswith(\".txt\"):\n",
        "            combined_text += read_txt(file_path)\n",
        "    return combined_text\n"
      ],
      "metadata": {
        "id": "Ly_QfYPDHlie",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.459323Z",
          "iopub.execute_input": "2024-02-20T07:25:24.459588Z",
          "iopub.status.idle": "2024-02-20T07:25:24.471904Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.459566Z",
          "shell.execute_reply": "2024-02-20T07:25:24.471138Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read documents from the directory\n",
        "#train_directory = '/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/training_data/full_text'\n",
        "train_directory = '/content/datasets/'\n",
        "text_data = read_documents_from_directory(train_directory)\n",
        "text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n"
      ],
      "metadata": {
        "id": "oobynnecHx87",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.475061Z",
          "iopub.execute_input": "2024-02-20T07:25:24.475847Z",
          "iopub.status.idle": "2024-02-20T07:25:24.489423Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.475814Z",
          "shell.execute_reply": "2024-02-20T07:25:24.488611Z"
        },
        "trusted": true
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text_data = read_pdf('/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/Cell_Biology.pdf')\n",
        "#text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters"
      ],
      "metadata": {
        "id": "YUR9VpCuE5GN",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.490482Z",
          "iopub.execute_input": "2024-02-20T07:25:24.490735Z",
          "iopub.status.idle": "2024-02-20T07:25:24.498196Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.490713Z",
          "shell.execute_reply": "2024-02-20T07:25:24.497346Z"
        },
        "trusted": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the training and validation data as text files\n",
        "#with open(\"/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/combined_text/full_text/train.txt\", \"w\") as f:\n",
        " #   f.write(text_data)"
      ],
      "metadata": {
        "id": "-ZaBPMO-GZQP",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.499408Z",
          "iopub.execute_input": "2024-02-20T07:25:24.499751Z",
          "iopub.status.idle": "2024-02-20T07:25:24.509665Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.499721Z",
          "shell.execute_reply": "2024-02-20T07:25:24.508703Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_file_path = '/content/datasets/dataset_indo.txt'\n",
        "with open(output_file_path, 'w') as f:\n",
        "    f.write(text_data)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.510727Z",
          "iopub.execute_input": "2024-02-20T07:25:24.510988Z",
          "iopub.status.idle": "2024-02-20T07:25:24.519602Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.510965Z",
          "shell.execute_reply": "2024-02-20T07:25:24.518739Z"
        },
        "trusted": true,
        "id": "O5bewGEgS3CG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/datasets/dataset_indo.txt\", \"w\") as f:\n",
        "    f.write(text_data)"
      ],
      "metadata": {
        "id": "8RCPr_L0uJdo",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.520647Z",
          "iopub.execute_input": "2024-02-20T07:25:24.520931Z",
          "iopub.status.idle": "2024-02-20T07:25:24.528908Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.520909Z",
          "shell.execute_reply": "2024-02-20T07:25:24.528195Z"
        },
        "trusted": true
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from transformers import Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "9MFaNgaDEVKP",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.529855Z",
          "iopub.execute_input": "2024-02-20T07:25:24.530129Z",
          "iopub.status.idle": "2024-02-20T07:25:24.538751Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.530107Z",
          "shell.execute_reply": "2024-02-20T07:25:24.537823Z"
        },
        "trusted": true
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path, tokenizer, block_size = 128):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer = tokenizer,\n",
        "        file_path = file_path,\n",
        "        block_size = block_size,\n",
        "    )\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Wk_14dI9EVdD",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.540014Z",
          "iopub.execute_input": "2024-02-20T07:25:24.540644Z",
          "iopub.status.idle": "2024-02-20T07:25:24.551966Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.540615Z",
          "shell.execute_reply": "2024-02-20T07:25:24.551157Z"
        },
        "trusted": true
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_collator(tokenizer, mlm = False):\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=mlm,\n",
        "    )\n",
        "    return data_collator"
      ],
      "metadata": {
        "id": "QJcoT-aNFcKp",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.553140Z",
          "iopub.execute_input": "2024-02-20T07:25:24.553403Z",
          "iopub.status.idle": "2024-02-20T07:25:24.562895Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.553381Z",
          "shell.execute_reply": "2024-02-20T07:25:24.562085Z"
        },
        "trusted": true
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_file_path,model_name,\n",
        "          output_dir,\n",
        "          overwrite_output_dir,\n",
        "          per_device_train_batch_size,\n",
        "          num_train_epochs,\n",
        "          save_steps):\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
        "  data_collator = load_data_collator(tokenizer)\n",
        "\n",
        "  tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "  model.save_pretrained(output_dir)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "          output_dir=output_dir,\n",
        "          overwrite_output_dir=overwrite_output_dir,\n",
        "          per_device_train_batch_size=per_device_train_batch_size,\n",
        "          num_train_epochs=num_train_epochs,\n",
        "      )\n",
        "\n",
        "  trainer = Trainer(\n",
        "          model=model,\n",
        "          args=training_args,\n",
        "          data_collator=data_collator,\n",
        "          train_dataset=train_dataset,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  trainer.save_model()"
      ],
      "metadata": {
        "id": "Ub3THjJ_FdSw",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.563916Z",
          "iopub.execute_input": "2024-02-20T07:25:24.564180Z",
          "iopub.status.idle": "2024-02-20T07:25:24.573211Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.564152Z",
          "shell.execute_reply": "2024-02-20T07:25:24.572367Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#train_file_path = \"/content/drive/MyDrive/ColabNotebooks/data/chatbot_docs/combined_text/full_text/train.txt\"\n",
        "train_file_path = \"/content/datasets/dataset_indo.txt\"\n",
        "model_name = 'gpt2'\n",
        "#output_dir = '/content/drive/MyDrive/ColabNotebooks/models/chat_models/custom_full_text'\n",
        "output_dir = '/content/output'\n",
        "overwrite_output_dir = False\n",
        "per_device_train_batch_size = 8\n",
        "num_train_epochs = 50.0\n",
        "save_steps = 50000"
      ],
      "metadata": {
        "id": "9mXiWKHbFr2f",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.576212Z",
          "iopub.execute_input": "2024-02-20T07:25:24.576470Z",
          "iopub.status.idle": "2024-02-20T07:25:24.583507Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.576448Z",
          "shell.execute_reply": "2024-02-20T07:25:24.582510Z"
        },
        "trusted": true
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-jF8h22Xr8M",
        "outputId": "5188819a-bd42-46f3-9ea9-db894855a26f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "train(\n",
        "    train_file_path=train_file_path,\n",
        "    model_name=model_name,\n",
        "    output_dir=output_dir,\n",
        "    overwrite_output_dir=overwrite_output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    save_steps=save_steps\n",
        ")"
      ],
      "metadata": {
        "id": "WMdaTo7KF9uo",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:25:24.584434Z",
          "iopub.execute_input": "2024-02-20T07:25:24.584681Z",
          "iopub.status.idle": "2024-02-20T07:27:54.872848Z",
          "shell.execute_reply.started": "2024-02-20T07:25:24.584660Z",
          "shell.execute_reply": "2024-02-20T07:27:54.871917Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "285b0408-b49d-4d6d-88ff-13540a2ab3de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:08, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "xwGS1IMlGBMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "lelq_sN4Gy5M",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:27:54.874257Z",
          "iopub.execute_input": "2024-02-20T07:27:54.874594Z",
          "iopub.status.idle": "2024-02-20T07:27:54.882786Z",
          "shell.execute_reply.started": "2024-02-20T07:27:54.874564Z",
          "shell.execute_reply": "2024-02-20T07:27:54.881902Z"
        },
        "trusted": true
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path):\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_tokenizer(tokenizer_path):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
        "    return tokenizer\n",
        "\n",
        "def generate_text(model_path, sequence, max_length):\n",
        "\n",
        "    model = load_model(model_path)\n",
        "    tokenizer = load_tokenizer(model_path)\n",
        "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
        "    final_outputs = model.generate(\n",
        "        ids,\n",
        "        do_sample=True,\n",
        "        max_length=max_length,\n",
        "        pad_token_id=model.config.eos_token_id,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "wOvrNQRAG2IP",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:27:54.884034Z",
          "iopub.execute_input": "2024-02-20T07:27:54.885705Z",
          "iopub.status.idle": "2024-02-20T07:27:54.894406Z",
          "shell.execute_reply.started": "2024-02-20T07:27:54.885680Z",
          "shell.execute_reply": "2024-02-20T07:27:54.893403Z"
        },
        "trusted": true
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1_path = \"/content/output\"\n",
        "sequence1 = \"how many island in indonesia?\"\n",
        "max_len = 50\n",
        "generate_text(model1_path, sequence1, max_len)"
      ],
      "metadata": {
        "id": "5mTDTrpnG5Ut",
        "outputId": "4a8b3aa2-b98a-489e-ddc5-cc326de83580",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:42:05.455785Z",
          "iopub.execute_input": "2024-02-20T07:42:05.456845Z",
          "iopub.status.idle": "2024-02-20T07:42:07.580881Z",
          "shell.execute_reply.started": "2024-02-20T07:42:05.456804Z",
          "shell.execute_reply": "2024-02-20T07:42:07.579674Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how many island in indonesia?\n",
            "Indonesia's northernmost province, Aceh, is a haven for those seeking refuge from the violence that follows the country's bloody civil war. This lush, humid environment, rich in wildlife and cultural\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following model was trained on 100 questions and answers based on the original text and it trained in a few seconds (50 epochs). It gives very meaningful results."
      ],
      "metadata": {
        "id": "dCxvbeKfRs35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2_path = \"/content/output\"\n",
        "sequence2 = \"what is the easternmost province in indonesia?\"\n",
        "max_len = 50\n",
        "generate_text(model2_path, sequence2, max_len)"
      ],
      "metadata": {
        "id": "uSAOQPk8vOTE",
        "outputId": "8035ab14-0a26-4a80-ea49-47565f41a828",
        "execution": {
          "iopub.status.busy": "2024-02-20T07:31:54.267185Z",
          "iopub.execute_input": "2024-02-20T07:31:54.267904Z",
          "iopub.status.idle": "2024-02-20T07:31:56.360013Z",
          "shell.execute_reply.started": "2024-02-20T07:31:54.267844Z",
          "shell.execute_reply": "2024-02-20T07:31:56.358824Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the easternmost province in indonesia? This question, with its dense and diverse rainforests, ancient cities, and inhospitable deserts, is the ultimate test of our nation's might.\n",
            "In the southern province of Surab\n"
          ]
        }
      ]
    }
  ]
}